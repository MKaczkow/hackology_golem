{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../data/m5_forecasting_accuracy'\n",
    "calendar = pd.read_csv(f'{INPUT_DIR}/calendar.csv')\n",
    "selling_prices_df = pd.read_csv(f'{INPUT_DIR}/sell_prices.csv')\n",
    "sample_submission = pd.read_csv(f'{INPUT_DIR}/sample_submission.csv')\n",
    "sales_train_val = pd.read_csv(f'{INPUT_DIR}/sales_train_validation.csv')\n",
    "sales_train_eval = pd.read_csv(f'{INPUT_DIR}/sales_train_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/janfidor/anaconda3/envs/hackology/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Pandas Apply: 100%|██████████| 1913/1913 [00:00<00:00, 2733.58it/s]\n",
      "Pandas Apply: 100%|██████████| 1941/1941 [00:00<00:00, 2891.44it/s]\n"
     ]
    }
   ],
   "source": [
    "from data_preprocessing import load_pivoted_dataframes, preprocess_missing_data, prepare_df_with_covariates\n",
    "\n",
    "pivoted_covariates = load_pivoted_dataframes(sales_train_val)\n",
    "selling_prices_df = preprocess_missing_data(selling_prices_df)\n",
    "\n",
    "sales_train_val_transposed1, non_sales_columns_val, sell_price_columns_val, sales_columns_val =\\\n",
    "                    prepare_df_with_covariates(sales_train_val, selling_prices_df, 'validation', calendar, pivoted_covariates)\n",
    "\n",
    "sales_train_eval_transposed1, non_sales_columns_eval, sell_price_columns_eval, sales_columns_eval =\\\n",
    "                    prepare_df_with_covariates(sales_train_eval, selling_prices_df, 'evaluation', calendar, pivoted_covariates)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_preprocessing import darts_preprocessing\n",
    "DATE_COLUMN = 'date'\n",
    "\n",
    "train_scaled, val_scaled, train_covariates_scaled, val_covariates_scaled, scaler_series_val, scaler_covariates_val, df_sales, df_covariates, label_encoders_val =\\\n",
    "            darts_preprocessing(sales_train_val_transposed1, None, None,\\\n",
    "                                sales_columns_val, non_sales_columns_val,\\\n",
    "                                sell_price_columns_val, 'validation', None)\n",
    "\n",
    "eval_scaled, eval_covariates_scaled, scaler_series_eval, scaler_covariates_eval, df_sales, df_covariates, label_encoders_eval =\\\n",
    "            darts_preprocessing(sales_train_eval_transposed1, scaler_series_val, scaler_covariates_val,\\\n",
    "                                sales_columns_eval,non_sales_columns_eval,\\\n",
    "                                sell_price_columns_eval, 'evaluation', label_encoders_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from darts.models import NHiTSModel\n",
    "from darts.models import NBEATSModel\n",
    "from darts.dataprocessing.transformers.scaler import Scaler\n",
    "from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
    "from darts.metrics import mae, mse\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "logging.disable(logging.CRITICAL)\n",
    "from pytorch_lightning.callbacks import Callback\n",
    "from darts.metrics import rmsle\n",
    "from torchmetrics import MeanSquaredError\n",
    "\n",
    "# stop training when validation loss does not decrease more than 0.05 (`min_delta`) over\n",
    "# a period of 5 epochs (`patience`)\n",
    "my_stopper = EarlyStopping(\n",
    "    monitor=\"train_MeanSquaredError\",\n",
    "    patience=20,\n",
    "    min_delta=0.002,\n",
    "    mode='min',\n",
    ")\n",
    "\n",
    "torch_metrics = MeanSquaredError()\n",
    "    \n",
    "# model = NHiTSModel(\n",
    "#     input_chunk_length=7,  # Example: trying three different input chunk lengths\n",
    "#     output_chunk_length=28,      # Example: trying two different output chunk lengths\n",
    "# #     num_blocks=2,             # Number of blocks in the N-HiTS architecture\n",
    "# #     num_layers=2,                # Number of layers in each block\n",
    "# #     layer_widths=16,           # Width of each layer    \n",
    "#     n_epochs=100,\n",
    "#     torch_metrics=torch_metrics,\n",
    "#     pl_trainer_kwargs={\n",
    "#                  \"accelerator\":\"gpu\",\n",
    "#                  \"devices\": -1,\n",
    "#                  \"callbacks\": [my_stopper]    \n",
    "#                  }        \n",
    "# )\n",
    "\n",
    "from darts.models import TCNModel\n",
    "from darts.models import BlockRNNModel\n",
    "from darts.models import TransformerModel\n",
    "\n",
    "model = TransformerModel(\n",
    "    input_chunk_length=1,\n",
    "    output_chunk_length=1,\n",
    "#     model = 'GRU', #(“RNN”, “LSTM” or “GRU”)    \n",
    "#     hidden_dim=15, \n",
    "#     n_rnn_layers=20,    \n",
    "    n_epochs=1,\n",
    "    optimizer_cls = torch.optim.Rprop,\n",
    "    torch_metrics=torch_metrics,\n",
    "    pl_trainer_kwargs={\n",
    "                 \"accelerator\":\"gpu\",\n",
    "                 \"devices\": -1,\n",
    "                 \"callbacks\": [my_stopper]    \n",
    "                 },\n",
    "    optimizer_kwargs ={\n",
    "        'lr': 1e-4,       \n",
    "    }    \n",
    ")\n",
    "\n",
    "model.fit(series=train_scaled, past_covariates=train_covariates_scaled,) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 48/48 [00:02<00:00, 20.68it/s, train_loss=0.0223]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TransformerModel(output_chunk_shift=0, d_model=64, nhead=4, num_encoder_layers=3, num_decoder_layers=3, dim_feedforward=512, dropout=0.1, activation=relu, norm_type=None, custom_encoder=None, custom_decoder=None, input_chunk_length=1, output_chunk_length=1, n_epochs=1, optimizer_cls=<class 'torch.optim.rprop.Rprop'>, torch_metrics=MeanSquaredError(), pl_trainer_kwargs={'accelerator': 'gpu', 'devices': -1, 'callbacks': [<pytorch_lightning.callbacks.early_stopping.EarlyStopping object at 0x73c73afab950>]}, optimizer_kwargs={'lr': 0.0001})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(series=train_scaled, past_covariates=train_covariates_scaled,) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hackology",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
